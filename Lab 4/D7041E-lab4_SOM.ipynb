{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEuclideanDistance(single_point,array):\n",
    "    nrows, ncols, nfeatures=array.shape[0],array.shape[1], array.shape[2]\n",
    "    points=array.reshape((nrows*ncols,nfeatures))\n",
    "                         \n",
    "    dist = (points - single_point)**2\n",
    "    dist = np.sum(dist, axis=1)\n",
    "    dist = np.sqrt(dist)\n",
    "\n",
    "    dist=dist.reshape((nrows,ncols))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mu, sigma = 0, 0.1\n",
    "A = np.random.normal(mu, sigma, 10)\n",
    "#A.shape, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows,ncols,nfeatures=3,3,3\n",
    "\n",
    "#Generate coordinate system\n",
    "x,y=np.meshgrid(range(ncols),range(nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sgm0=2\n",
    "sgmdecay=0.05\n",
    "t=1\n",
    "sgm = sgm0 * math.exp(-t*sgmdecay);\n",
    "\n",
    "width = math.ceil(sgm*3)\n",
    "\n",
    "dist=np.array([[2,1,3],[3,2,3],[4,4,4]])\n",
    "bmurow, bmucol =np.unravel_index(np.argmin(dist, axis=None), dist.shape) \n",
    "\n",
    "g = np.exp(-((np.power(x - bmucol,2)) + (np.power(y - bmurow,2))) / (2*sgm*sgm));\n",
    "\n",
    "\n",
    "fromrow = max(0,bmurow - width);\n",
    "torow   = min(bmurow + width,nrows);\n",
    "fromcol = max(0,bmucol - width);\n",
    "tocol   = min(bmucol + width,ncols);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.dstack([g[fromrow:torow,fromcol:tocol]]*nfeatures);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOM (dispRes, trainingData, ndim=10, nepochs=10, eta0=0.1, etadecay=0.05, sgm0=20, sgmdecay=0.05, showMode=0):\n",
    "    nfeatures=trainingData.shape[1]\n",
    "    ntrainingvectors=trainingData.shape[0]\n",
    "    \n",
    "    nrows = ndim\n",
    "    ncols = ndim\n",
    "    \n",
    "    mu, sigma = 0, 0.1\n",
    "    numpy.random.seed(int(time.time()))\n",
    "    som = np.random.normal(mu, sigma, (nrows,ncols,nfeatures))\n",
    "\n",
    "    if showMode >= 1:\n",
    "        print(\"\\nSOM features before training: \\n\")\n",
    "        \n",
    "        fig, ax=plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,15))\n",
    "        \n",
    "        for k in range(nrows):\n",
    "            for l in range (ncols):\n",
    "                A=som[k,l,:].reshape((dispRes[0],dispRes[1]))\n",
    "                ax[k,l].imshow(A,cmap=\"plasma\")\n",
    "                ax[k,l].set_yticks([])\n",
    "                ax[k,l].set_xticks([])   \n",
    "    \n",
    "    #Generate coordinate system\n",
    "    x,y=np.meshgrid(range(ncols),range(nrows))\n",
    "    \n",
    "    \n",
    "    for t in range (1,nepochs+1):\n",
    "        #Compute the learning rate for the current epoch\n",
    "        eta = eta0 * math.exp(-t*etadecay);\n",
    "        \n",
    "        #Compute the variance of the Gaussian (Neighbourhood) function for the ucrrent epoch\n",
    "        sgm = sgm0 * math.exp(-t*sgmdecay);\n",
    "        \n",
    "        #Consider the width of the Gaussian function as 3 sigma\n",
    "        width = math.ceil(sgm*3);\n",
    "        \n",
    "        for ntraining in range(ntrainingvectors):\n",
    "            trainingVector = trainingData[ntraining,:];\n",
    "            \n",
    "            # Compute the Euclidean distance between the training vector and\n",
    "            # each neuron in the SOM map\n",
    "            dist = getEuclideanDistance(trainingVector, som);\n",
    "       \n",
    "            # Find 2D coordinates of the Best Matching Unit (bmu)\n",
    "            bmurow, bmucol =np.unravel_index(np.argmin(dist, axis=None), dist.shape) ;\n",
    "            \n",
    "            \n",
    "            #Generate a Gaussian function centered on the location of the bmu\n",
    "            g = np.exp(-((np.power(x - bmucol,2)) + (np.power(y - bmurow,2))) / (2*sgm*sgm));\n",
    "\n",
    "            #Determine the boundary of the local neighbourhood\n",
    "            fromrow = max(0,bmurow - width);\n",
    "            torow   = min(bmurow + width,nrows);\n",
    "            fromcol = max(0,bmucol - width);\n",
    "            tocol   = min(bmucol + width,ncols);\n",
    "\n",
    "            \n",
    "            #Get the neighbouring neurons and determine the size of the neighbourhood\n",
    "            neighbourNeurons = som[fromrow:torow,fromcol:tocol,:];\n",
    "            sz = neighbourNeurons.shape;\n",
    "            \n",
    "            #Transform the training vector and the Gaussian function into \n",
    "            # multi-dimensional to facilitate the computation of the neuron weights update\n",
    "            T = np.matlib.repmat(trainingVector,sz[0]*sz[1],1).reshape((sz[0],sz[1],nfeatures));                   \n",
    "            G = np.dstack([g[fromrow:torow,fromcol:tocol]]*nfeatures);\n",
    "\n",
    "            # Update the weights of the neurons that are in the neighbourhood of the bmu\n",
    "            neighbourNeurons = neighbourNeurons + eta * G * (T - neighbourNeurons);\n",
    "\n",
    "            \n",
    "            #Put the new weights of the BMU neighbouring neurons back to the\n",
    "            #entire SOM map\n",
    "            som[fromrow:torow,fromcol:tocol,:] = neighbourNeurons;\n",
    "\n",
    "    if showMode >= 1:\n",
    "        print(\"\\nSOM features AFTER training: \\n\")\n",
    "        \n",
    "        fig, ax=plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,15))\n",
    "        \n",
    "        for k in range(nrows):\n",
    "            for l in range (ncols):\n",
    "                A=som[k,l,:].reshape((dispRes[0],dispRes[1]))\n",
    "                ax[k,l].imshow(A,cmap=\"plasma\")\n",
    "                ax[k,l].set_yticks([])\n",
    "            ax[k,l].set_xticks([])   \n",
    "    return som\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def parse_input_zoo_data(filename, header='infer'):\n",
    "\n",
    "    input_data = pd.read_csv(filename, header=header)\n",
    "\n",
    "    classes = input_data[17].tolist()\n",
    "    labels = input_data[0].tolist()\n",
    "    input_database = {\n",
    "        0: input_data.as_matrix([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])\n",
    "    }\n",
    "\n",
    "    return input_database, labels, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/zoo.txt' does not exist: b'data/zoo.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-aea79de737ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/zoo.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_vector_database\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_input_zoo_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6fa546904275>\u001b[0m in \u001b[0;36mparse_input_zoo_data\u001b[0;34m(filename, header)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_input_zoo_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    695\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/zoo.txt' does not exist: b'data/zoo.txt'"
     ]
    }
   ],
   "source": [
    "input_filename = 'data/zoo.txt'\n",
    "input_vector_database, labels, classes = parse_input_zoo_data(input_filename,None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#som_trained=SOM ([4,4],input_vector_database[0], ndim=10, nepochs=100, eta0=0.01, etadecay=0.05, sgm0=20, sgmdecay=0.05, showMode=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verification of correctness on the training set:\n",
    "\n",
    "\n",
    "\n",
    "def SOM_Test (trainingData, som_, classes, grid_, ConfusionMatrix, ndim=60):\n",
    "    nfeatures=trainingData.shape[1]\n",
    "    ntrainingvectors=trainingData.shape[0]\n",
    "    \n",
    "    nrows = ndim\n",
    "    ncols = ndim\n",
    "    \n",
    "    nclasses=np.max(classes)\n",
    "\n",
    "    som_cl=np.zeros((ndim,ndim,nclasses+1))\n",
    "    \n",
    "    \n",
    "    for ntraining in range(ntrainingvectors):\n",
    "        trainingVector = trainingData[ntraining,:];\n",
    "        class_of_sample= classes[ntraining]    \n",
    "        # Compute the Euclidean distance between the training vector and\n",
    "        # each neuron in the SOM map\n",
    "        dist = getEuclideanDistance(trainingVector, som_);\n",
    "       \n",
    "        # Find 2D coordinates of the Best Matching Unit (bmu)\n",
    "        bmurow, bmucol =np.unravel_index(np.argmin(dist, axis=None), dist.shape) ;\n",
    "        \n",
    "        \n",
    "        som_cl[bmurow, bmucol,class_of_sample]=som_cl[bmurow, bmucol,class_of_sample]+1\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range (nrows):\n",
    "        for j in range (ncols):\n",
    "            grid_[i,j]=np.argmax(som_cl[i,j,:])\n",
    "\n",
    " \n",
    "    for ntraining in range(ntrainingvectors):\n",
    "        trainingVector = trainingData[ntraining,:];\n",
    "        class_of_sample= classes[ntraining]    \n",
    "        # Compute the Euclidean distance between the training vector and\n",
    "        # each neuron in the SOM map\n",
    "        dist = getEuclideanDistance(trainingVector, som_);\n",
    "       \n",
    "        # Find 2D coordinates of the Best Matching Unit (bmu)\n",
    "        bmurow, bmucol =np.unravel_index(np.argmin(dist, axis=None), dist.shape) ;\n",
    "        \n",
    "        predicted=np.argmax(som_cl[bmurow, bmucol,:])\n",
    "        ConfusionMatrix[class_of_sample-1, predicted-1]=ConfusionMatrix[class_of_sample-1, predicted-1]+1\n",
    "        \n",
    "    return grid_, ConfusionMatrix\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim=10\n",
    "nrows=ndim\n",
    "ncols=ndim\n",
    "grid_color=np.zeros((nrows,ncols))\n",
    "nclasses=np.max(classes)\n",
    "\n",
    "Confusion_Matrix=np.zeros((nclasses,nclasses))\n",
    "grid_color,Confusion_Matrix=SOM_Test (input_vector_database[0], som_trained, classes, grid_color, Confusion_Matrix, ndim)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.imshow(grid_color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion_Matrix, input_vector_database[0].shape, np.sum(Confusion_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
